====== Training Started ======
====== Training Started ======
====== Training Started ======
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (46007, 31)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40787, 31), Test set: (5220, 31)
====== Training Started ======
Loaded data with shape: (44820, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (40337, 30), Test set: (4483, 30)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (18538, 30), Test set: (1426, 30)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (18538, 30), Test set: (1426, 30)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using year 2023 as test set
Train set: (18538, 30), Test set: (1426, 30)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
===== 模型评估指标 =====
AUC: 0.6592
F1-score: 0.0962
Sensitivity (Recall): 0.8000
Specificity: 0.5722
Precision: 0.0512
Accuracy: 0.5785
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2017 2018 2019 2020 2021 2022 2023] for creating test windows
Using years [2010 2011 2012 2013 2014 2015 2016] for creating validation windows
Using years [] for creating training windows
Train data shape: (0, 30)
Validation data shape: (9982, 30)
Test data shape: (9982, 30)
Created 0 training samples
Created 1426 validation samples
Created 1426 test samples
ERROR: Failed to create valid sliding window samples. Check year continuity.
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: False
Training with Class Weights: True
Validation Accuracy: 0.9593
Validation F1 Score: 0.5797
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      1340
         1.0       0.77      0.47      0.58        86

    accuracy                           0.96      1426
   macro avg       0.87      0.73      0.78      1426
weighted avg       0.95      0.96      0.95      1426

Test Accuracy: 0.9067
Test F1 Score: 0.2400
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.92      0.95      1386
         1.0       0.16      0.53      0.24        40

    accuracy                           0.91      1426
   macro avg       0.57      0.72      0.60      1426
weighted avg       0.96      0.91      0.93      1426

Training metrics saved to results/training_metrics.csv
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
Model configuration saved to results/model_config.json
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: True
Training with Class Weights: True
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: True
Training with Class Weights: True
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: True
Training with Class Weights: True
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: True
Training with Class Weights: True
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Using Enhanced LSTM Model: True
Training with Focal Loss: True
Training with F1 Loss: True
Training with Class Weights: True
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Task type: Classification
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.5645
Validation AUC: 0.7419
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test F1 Score: 0.2131
Test AUC: 0.6376
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.5645
Validation AUC: 0.7419
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.9551
Validation AUC: 0.7419
Validation Sensitivity: 0.4070
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test F1 Score (weighted): 0.9437
Test F1 Score (macro): 0.5890
Test AUC: 0.6376
Test Sensitivity: 0.3250
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation F1 Score: 0.9391
Validation AUC: 0.9016
Validation Sensitivity: 0.6279
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test F1 Score (weighted): 0.9263
Test F1 Score (macro): 0.6047
Test AUC: 0.8438
Test Sensitivity: 0.6500
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation F1 Score: 0.9391
Validation AUC: 0.9016
Validation Sensitivity: 0.6279
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test F1 Score (weighted): 0.9263
Test F1 Score (macro): 0.6047
Test AUC: 0.8438
Test Sensitivity: 0.6500
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation F1 Score: 0.9391
Validation AUC: 0.9016
Validation Sensitivity: 0.6279
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test F1 Score (weighted): 0.9263
Test F1 Score (macro): 0.6047
Test AUC: 0.8438
Test Sensitivity: 0.6500
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.9551
Validation AUC: 0.7419
Validation Sensitivity: 0.4070
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test F1 Score (weighted): 0.9437
Test F1 Score (macro): 0.5890
Test AUC: 0.6376
Test Sensitivity: 0.3250
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.9551
Validation AUC: 0.7419
Validation Sensitivity: 0.4070
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test F1 Score (weighted): 0.9437
Test F1 Score (macro): 0.5890
Test AUC: 0.6376
Test Sensitivity: 0.3250
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation F1 Score: 0.9391
Validation AUC: 0.9016
Validation Sensitivity: 0.6279
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test F1 Score (weighted): 0.9263
Test F1 Score (macro): 0.6047
Test AUC: 0.8438
Test Sensitivity: 0.6500
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Label 0 count: 8401
Label 1 count: 155
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 8401
After SMOTE: Label 1 count: 8401
Validation F1 Score: 0.9391
Validation AUC: 0.9016
Validation Sensitivity: 0.6279
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1340
         1.0       0.47      0.63      0.54        86

    accuracy                           0.93      1426
   macro avg       0.72      0.79      0.75      1426
weighted avg       0.95      0.93      0.94      1426

Validation Accuracy: 0.9348
Test F1 Score (weighted): 0.9263
Test F1 Score (macro): 0.6047
Test AUC: 0.8438
Test Sensitivity: 0.6500
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.91      0.95      1386
         1.0       0.17      0.65      0.26        40

    accuracy                           0.90      1426
   macro avg       0.58      0.78      0.60      1426
weighted avg       0.97      0.90      0.93      1426

Test Accuracy: 0.8983
Test predictions saved to results/test_predictions.csv
Model saved to results/lstm_model_final.pt
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Using years [2021 2022 2023] for creating test windows
Using years [2018 2019 2020] for creating validation windows
Using years [2010 2011 2012 2013 2014 2015 2016 2017] for creating training windows
Train data shape: (11408, 30)
Validation data shape: (4278, 30)
Test data shape: (4278, 30)
Created 8556 training samples
Created 1426 validation samples
Created 1426 test samples
Training data: (8556, 2, 27), (8556,)
Validation data: (1426, 2, 27), (1426,)
Testing data: (1426, 2, 27), (1426,)
Validation F1 Score: 0.9551
Validation AUC: 0.7419
Validation Sensitivity: 0.4070
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98      1340
         1.0       0.92      0.41      0.56        86

    accuracy                           0.96      1426
   macro avg       0.94      0.70      0.77      1426
weighted avg       0.96      0.96      0.96      1426

Validation Accuracy: 0.9621
Test F1 Score (weighted): 0.9437
Test F1 Score (macro): 0.5890
Test AUC: 0.6376
Test Sensitivity: 0.3250
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.96      1386
         1.0       0.16      0.33      0.21        40

    accuracy                           0.93      1426
   macro avg       0.57      0.64      0.59      1426
weighted avg       0.96      0.93      0.94      1426

Test Accuracy: 0.9327
Test predictions saved to results/test_predictions.csv
Model saved to results/cusboost_model_final.pkl
====== Training Completed ======
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 17112 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 11408
Validation samples: 2852
Test samples: 2852
Training data: (11408, 2, 27), (11408,)
Validation data: (2852, 2, 27), (2852,)
Testing data: (2852, 2, 27), (2852,)
Validation F1 Score: 0.9568
Validation AUC: 0.8270
Validation Sensitivity: 0.4245
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      2713
         1.0       0.65      0.42      0.51       139

    accuracy                           0.96      2852
   macro avg       0.81      0.71      0.75      2852
weighted avg       0.96      0.96      0.96      2852

Validation Accuracy: 0.9607
Test F1 Score (weighted): 0.9463
Test F1 Score (macro): 0.6448
Test AUC: 0.7247
Test Sensitivity: 0.5000
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.97      2764
         1.0       0.24      0.50      0.32        88

    accuracy                           0.94      2852
   macro avg       0.61      0.72      0.64      2852
weighted avg       0.96      0.94      0.95      2852

Test Accuracy: 0.9355
====== Training Started ======
Loaded data with shape: (44820, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 34375 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 18819
Validation samples: 7062
Test samples: 8494
Training data: (18819, 2, 27), (18819,)
Validation data: (7062, 2, 27), (7062,)
Testing data: (8494, 2, 27), (8494,)
Validation F1 Score: 0.9407
Validation AUC: 0.8976
Validation Sensitivity: 0.1928
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.96      0.99      0.98      6699
         1.0       0.64      0.19      0.30       363

    accuracy                           0.95      7062
   macro avg       0.80      0.59      0.64      7062
weighted avg       0.94      0.95      0.94      7062

Validation Accuracy: 0.9528
Test F1 Score (weighted): 0.9583
Test F1 Score (macro): 0.6145
Test AUC: 0.6213
Test Sensitivity: 0.2664
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.98      0.98      8265
         1.0       0.24      0.27      0.25       229

    accuracy                           0.96      8494
   macro avg       0.61      0.62      0.61      8494
weighted avg       0.96      0.96      0.96      8494

Test Accuracy: 0.9571
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 27), (17867,)
Validation data: (6701, 2, 27), (6701,)
Testing data: (8023, 2, 27), (8023,)
Validation F1 Score: 0.9596
Validation AUC: 0.7579
Validation Sensitivity: 0.3610
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      6424
         1.0       0.61      0.36      0.45       277

    accuracy                           0.96      6701
   macro avg       0.79      0.68      0.72      6701
weighted avg       0.96      0.96      0.96      6701

Validation Accuracy: 0.9640
Test F1 Score (weighted): 0.9621
Test F1 Score (macro): 0.6529
Test AUC: 0.6860
Test Sensitivity: 0.3990
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.97      0.98      7820
         1.0       0.28      0.40      0.33       203

    accuracy                           0.96      8023
   macro avg       0.63      0.69      0.65      8023
weighted avg       0.97      0.96      0.96      8023

Test Accuracy: 0.9585
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 27), (17867,)
Validation data: (6701, 2, 27), (6701,)
Testing data: (8023, 2, 27), (8023,)
Validation F1 Score: 0.9596
Validation AUC: 0.7579
Validation Sensitivity: 0.3610
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      6424
         1.0       0.61      0.36      0.45       277

    accuracy                           0.96      6701
   macro avg       0.79      0.68      0.72      6701
weighted avg       0.96      0.96      0.96      6701

Validation Accuracy: 0.9640
Test F1 Score (weighted): 0.9621
Test F1 Score (macro): 0.6529
Test AUC: 0.6860
Test Sensitivity: 0.3990
Confusion Matrix: [[7609  211]
 [ 122   81]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.97      0.98      7820
         1.0       0.28      0.40      0.33       203

    accuracy                           0.96      8023
   macro avg       0.63      0.69      0.65      8023
weighted avg       0.97      0.96      0.96      8023

Test Accuracy: 0.9585
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 27), (17867,)
Validation data: (6701, 2, 27), (6701,)
Testing data: (8023, 2, 27), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 17513
After SMOTE: Label 1 count: 17513
Validation F1 Score: 0.9562
Validation AUC: 0.9001
Validation Sensitivity: 0.5560
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.97      0.98      6424
         1.0       0.45      0.56      0.50       277

    accuracy                           0.95      6701
   macro avg       0.72      0.76      0.74      6701
weighted avg       0.96      0.95      0.96      6701

Validation Accuracy: 0.9540
Test F1 Score (weighted): 0.9458
Test F1 Score (macro): 0.6305
Test AUC: 0.8517
Test Sensitivity: 0.5961
Confusion Matrix: [[7333  487]
 [  82  121]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.94      0.96      7820
         1.0       0.20      0.60      0.30       203

    accuracy                           0.93      8023
   macro avg       0.59      0.77      0.63      8023
weighted avg       0.97      0.93      0.95      8023

Test Accuracy: 0.9291
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 0), (17867,)
Validation data: (6701, 2, 0), (6701,)
Testing data: (8023, 2, 0), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 0), (17867,)
Validation data: (6701, 2, 0), (6701,)
Testing data: (8023, 2, 0), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 0), (17867,)
Validation data: (6701, 2, 0), (6701,)
Testing data: (8023, 2, 0), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 0), (17867,)
Validation data: (6701, 2, 0), (6701,)
Testing data: (8023, 2, 0), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 0), (17867,)
Validation data: (6701, 2, 0), (6701,)
Testing data: (8023, 2, 0), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
ERROR: X_train_2d.shape[1] is 0. Check FEATURE_COLUMNS or X_train shape.
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 38), (17867,)
Validation data: (6701, 2, 38), (6701,)
Testing data: (8023, 2, 38), (8023,)
Label 0 count: 17513
Label 1 count: 354
Applying SMOTE oversampling to balance dataset
After SMOTE: Label 0 count: 17513
After SMOTE: Label 1 count: 17513
Validation F1 Score: 0.8613
Validation AUC: 0.7943
Validation Sensitivity: 0.4729
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.82      0.89      6424
         1.0       0.10      0.47      0.17       277

    accuracy                           0.81      6701
   macro avg       0.54      0.65      0.53      6701
weighted avg       0.94      0.81      0.86      6701

Validation Accuracy: 0.8075
Test F1 Score (weighted): 0.7838
Test F1 Score (macro): 0.4411
Test AUC: 0.6945
Test Sensitivity: 0.5616
Confusion Matrix: [[5295 2525]
 [  89  114]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.68      0.80      7820
         1.0       0.04      0.56      0.08       203

    accuracy                           0.67      8023
   macro avg       0.51      0.62      0.44      8023
weighted avg       0.96      0.67      0.78      8023

Test Accuracy: 0.6742
====== Training Started ======
Loaded data with shape: (43350, 41)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 32591 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 17867
Validation samples: 6701
Test samples: 8023
Training data: (17867, 2, 38), (17867,)
Validation data: (6701, 2, 38), (6701,)
Testing data: (8023, 2, 38), (8023,)
Validation F1 Score: 0.9622
Validation AUC: 0.7636
Validation Sensitivity: 0.3935
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      6424
         1.0       0.65      0.39      0.49       277

    accuracy                           0.97      6701
   macro avg       0.81      0.69      0.74      6701
weighted avg       0.96      0.97      0.96      6701

Validation Accuracy: 0.9663
Test F1 Score (weighted): 0.9621
Test F1 Score (macro): 0.6549
Test AUC: 0.6907
Test Sensitivity: 0.4089
Confusion Matrix: [[7605  215]
 [ 120   83]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.97      0.98      7820
         1.0       0.28      0.41      0.33       203

    accuracy                           0.96      8023
   macro avg       0.63      0.69      0.65      8023
weighted avg       0.97      0.96      0.96      8023

Test Accuracy: 0.9582
====== Training Started ======
Loaded data with shape: (19964, 30)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 17112 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 11408
Validation samples: 2852
Test samples: 2852
Training data: (11408, 2, 27), (11408,)
Validation data: (2852, 2, 27), (2852,)
Testing data: (2852, 2, 27), (2852,)
Validation F1 Score: 0.9568
Validation AUC: 0.8270
Validation Sensitivity: 0.4245
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      0.99      0.98      2713
         1.0       0.65      0.42      0.51       139

    accuracy                           0.96      2852
   macro avg       0.81      0.71      0.75      2852
weighted avg       0.96      0.96      0.96      2852

Validation Accuracy: 0.9607
Test F1 Score (weighted): 0.9463
Test F1 Score (macro): 0.6448
Test AUC: 0.7247
Test Sensitivity: 0.5000
Confusion Matrix: [[2624  140]
 [  44   44]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.95      0.97      2764
         1.0       0.24      0.50      0.32        88

    accuracy                           0.94      2852
   macro avg       0.61      0.72      0.64      2852
weighted avg       0.96      0.94      0.95      2852

Test Accuracy: 0.9355
====== Training Started ======
Loaded data with shape: (15904, 42)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 13632 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 9088
Validation samples: 2272
Test samples: 2272
Training data: (9088, 2, 27), (9088,)
Validation data: (2272, 2, 27), (2272,)
Testing data: (2272, 2, 27), (2272,)
Validation F1 Score: 0.9659
Validation AUC: 0.7431
Validation Sensitivity: 0.4048
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.99      0.98      2188
         1.0       0.63      0.40      0.49        84

    accuracy                           0.97      2272
   macro avg       0.80      0.70      0.74      2272
weighted avg       0.96      0.97      0.97      2272

Validation Accuracy: 0.9692
Test F1 Score (weighted): 0.9581
Test F1 Score (macro): 0.6046
Test AUC: 0.6493
Test Sensitivity: 0.3333
Confusion Matrix: [[2144   77]
 [  34   17]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.98      0.97      0.97      2221
         1.0       0.18      0.33      0.23        51

    accuracy                           0.95      2272
   macro avg       0.58      0.65      0.60      2272
weighted avg       0.97      0.95      0.96      2272

Test Accuracy: 0.9511
====== Training Started ======
Loaded data with shape: (15904, 42)
Years in dataset: [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023]
Created 13632 total samples
Target years in samples: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019. 2020. 2021. 2022. 2023.]
Train years: [2012. 2013. 2014. 2015. 2016. 2017. 2018. 2019.]
Validation years: [2020. 2021.]
Test years: [2022. 2023.]
Train samples: 9088
Validation samples: 2272
Test samples: 2272
Training data: (9088, 2, 27), (9088,)
Validation data: (2272, 2, 27), (2272,)
Testing data: (2272, 2, 27), (2272,)
Validation F1 Score: 0.9613
Validation AUC: 0.8047
Validation Sensitivity: 0.2381
Validation Classification Report:
              precision    recall  f1-score   support

         0.0       0.97      1.00      0.98      2188
         1.0       0.77      0.24      0.36        84

    accuracy                           0.97      2272
   macro avg       0.87      0.62      0.67      2272
weighted avg       0.96      0.97      0.96      2272

Validation Accuracy: 0.9692
Test F1 Score (weighted): 0.9482
Test F1 Score (macro): 0.6011
Test AUC: 0.7067
Test Sensitivity: 0.4706
Confusion Matrix: [[2094  127]
 [  27   24]]
Test Classification Report:
              precision    recall  f1-score   support

         0.0       0.99      0.94      0.96      2221
         1.0       0.16      0.47      0.24        51

    accuracy                           0.93      2272
   macro avg       0.57      0.71      0.60      2272
weighted avg       0.97      0.93      0.95      2272

Test Accuracy: 0.9322
